{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d3048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the required libraries.\n",
    "\n",
    "import csv\n",
    "import bs4\n",
    "import nltk\n",
    "import string\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6a146d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>963 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL\n",
       "0      37.0  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38.0  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39.0  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40.0  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41.0  https://insights.blackcoffer.com/will-ai-repla...\n",
       "..      ...                                                ...\n",
       "958     NaN                                                NaN\n",
       "959     NaN                                                NaN\n",
       "960     NaN                                                NaN\n",
       "961     NaN                                                NaN\n",
       "962     NaN                                                NaN\n",
       "\n",
       "[963 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input.xlsx is converted to input.csv and uploaded to dataframe.\n",
    "\n",
    "df = pd.read_csv('input.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80655204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nan is dropped from dataframe\n",
    "\n",
    "df = df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1332de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL present in the dataframe is copied to url_list in form of a list.\n",
    "\n",
    "url_list = [url for url in df['URL']]\n",
    "\n",
    "# The URL present in url_list are accessed by chrome and complete HTML code for said page is stored in text form and in a list \n",
    "# called text and according to the serial in which url was saved in url_list.\n",
    "\n",
    "text = []\n",
    "for url in url_list:\n",
    "    text.append(requests.get(url,headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7a414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unrequired part of HTML code present in text is removed using .content,'html.parser'.\n",
    "\n",
    "for i in range(len(text)):\n",
    "    text[i] = bs4.BeautifulSoup(text[i].content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56413e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The required paragraph is copied to list called articles by finding and specifying the class in HTML under which \n",
    "# the paragraph is present.\n",
    "\n",
    "articles = []\n",
    "for text in text:\n",
    "    articles.append(text.find('div', attrs = {'class':'td-post-content'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8e356ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "20\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "# articles list is checked for Null value and their position.\n",
    "\n",
    "for i in range(len(articles)):\n",
    "    if(articles[i] == None):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f491de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 3 indexes at which null value were found are dropped from database to prevent error in further code.\n",
    "\n",
    "df = df.drop([df.index[7], df.index[20],df.index[107]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967e5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The null values are dropped from articles list and copied to a new list called new_article.\n",
    "\n",
    "new_article = []\n",
    "for val in articles:\n",
    "    if val != None :\n",
    "        new_article.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bad9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML code is completely removed by using \".text\" and \\n present after removing the code is replaced by space(' '). \n",
    "# The remaining data in new_article is the data required for sentiment analysis.\n",
    "\n",
    "for i in range(len(new_article)):\n",
    "    new_article[i]= new_article[i].text.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e4aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new list called stop_words is formed and the stop words provided in form of multiple text files are added to stop_words \n",
    "# list.\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "stopWordsFile1 = 'StopWords_Auditor.txt'\n",
    "for stop_word in open(stopWordsFile1, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "\n",
    "stopWordsFile2 = 'StopWords_Currencies.txt'\n",
    "for stop_word in open(stopWordsFile2, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "\n",
    "stopWordsFile3 = 'StopWords_Generic.txt'\n",
    "for stop_word in open(stopWordsFile3, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "\n",
    "stopWordsFile4 = 'StopWords_GenericLong.txt'\n",
    "for stop_word in open(stopWordsFile4, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "\n",
    "stopWordsFile5= 'StopWords_DatesandNumbers.txt'\n",
    "for stop_word in open(stopWordsFile5, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "\n",
    "stopWordsFile6= 'StopWords_Geographic.txt'\n",
    "for stop_word in open(stopWordsFile6, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())\n",
    "    \n",
    "stopWordsFile7= 'StopWords_Names.txt'\n",
    "for stop_word in open(stopWordsFile7, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f358f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It saves the different number of sentences present in differet paragraphs present in new_article list. \n",
    "# The number of sentences is further saved in a new list called sentences.  \n",
    "\n",
    "sentences = []\n",
    "for article in new_article:\n",
    "    sentences.append(len(sent_tokenize(article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e27e2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_articles = [' ']*len(new_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b55dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markings such as '?', '.',',' and '!' are replaced with space(' '). \n",
    "\n",
    "for i in range(len(new_article)):\n",
    "    for w in stop_words:\n",
    "        cleaned_articles[i]= new_article[i].replace('?',' ').replace('.',' ').replace(',',' ').replace('!',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b521ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new list called words is created and number of words present in the differet paragraphs is present in new_article list\n",
    "# is saved into the words list\n",
    "\n",
    "words = []\n",
    "for article in new_article:\n",
    "    words.append(len(word_tokenize(article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e2ce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new list called words_cleaned is used to store number of words from cleaned_articles.\n",
    "\n",
    "words_cleaned = []\n",
    "for article in cleaned_articles:\n",
    "    words_cleaned.append(len(word_tokenize(article)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86f14252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive words and negative words are copied from positive-words.txt and negative-words.txt respectively and \n",
    "# stored in new lists called positive_words and negative_words respectively. Further positive score and negative\n",
    "# score are calculated by finding postive words and negative words in respectively in the cleaned_article list.\n",
    "\n",
    "positive_words = []\n",
    "negative_words = []\n",
    "\n",
    "positiveWordsFile = 'positive-words.txt'\n",
    "for positive_word in open(positiveWordsFile, 'r').readlines():\n",
    "    positive_words.append(positive_word.rstrip())\n",
    "    \n",
    "positive_score = [0]*len(new_article)\n",
    "for i in range(len(new_article)):\n",
    "    for word in positive_words:\n",
    "        for letter in cleaned_articles[i].lower().split(' '):\n",
    "            if letter==word:\n",
    "                positive_score[i]+=1\n",
    "\n",
    "negativeWordsFile = 'negative-words.txt'\n",
    "for negative_word in open(negativeWordsFile, 'r').readlines():\n",
    "    negative_words.append(negative_word.rstrip())\n",
    "    \n",
    "negative_score = [0]*len(new_article)\n",
    "for i in range(len(new_article)):\n",
    "    for word in negative_words:\n",
    "        for letter in cleaned_articles[i].lower().split(' '):\n",
    "            if letter==word:\n",
    "                negative_score[i]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6589498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_cleaned = np.array(words_cleaned)\n",
    "sentences = np.array(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a98ea8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['POSITIVE SCORE'] = positive_score\n",
    "df['NEGATIVE SCORE'] = negative_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25832325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['POLARITY SCORE'] = (df['POSITIVE SCORE']-df['NEGATIVE SCORE'])/ ((df['POSITIVE SCORE'] +df['NEGATIVE SCORE']) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c35014c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SUBJECTIVITY SCORE'] = (df['POSITIVE SCORE'] + df['NEGATIVE SCORE'])/( (words_cleaned) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d73ee481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AVG SENTENCE LENGTH'] = np.array(words)/np.array(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a12c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex words and syllables are counted here for calculating percentage of complex words, fog index, complex word count \n",
    "# and syllables per word.\n",
    "\n",
    "complex_words = []\n",
    "syllables_counts = []\n",
    "for article in new_article:\n",
    "    syllables_count = 0\n",
    "    d=article.split()\n",
    "    ans=0\n",
    "    for word in d:\n",
    "        count=0\n",
    "        for i in range(len(word)):\n",
    "            if(word[i]=='a' or word[i]=='e' or word[i] =='i' or word[i] == 'o' or word[i] == 'u'):\n",
    "                count+=1\n",
    "            if(i==len(word)-2 and (word[i]=='e' and word[i+1]=='d')):\n",
    "                count-=1\n",
    "            if(i==len(word)-2 and (word[i]=='e' and word[i]=='s')):\n",
    "                count-=1\n",
    "        syllables_count+=count   \n",
    "        if(count>2):\n",
    "            ans+=1\n",
    "    syllables_counts.append(syllables_count)\n",
    "    complex_words.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdb8c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERCENTAGE OF COMPLEX WORDS'] = np.array(complex_words)/np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c1efcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FOG INDEX'] = 0.4 * (df['AVG SENTENCE LENGTH'] + df['PERCENTAGE OF COMPLEX WORDS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad7023e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AVG NUMBER OF WORDS PER SENTENCES'] = df['AVG SENTENCE LENGTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32c87b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COMPLEX WORD COUNT'] = complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a079164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WORD COUNT'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6786d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SYLLABLE PER WORD'] = np.array(syllables_counts)/np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37487de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of characters are calculated for every paragraph and stored in list called total_characters.\n",
    "\n",
    "total_characters = []\n",
    "for article in new_article:\n",
    "    characters = 0\n",
    "    for word in article.split():\n",
    "        characters+=len(word)\n",
    "    total_characters.append(characters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8061db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of personal noun are counted and stored in a list called personal_nouns.\n",
    "\n",
    "personal_nouns = []\n",
    "personal_noun =['I', 'we','my', 'ours','and' 'us', 'We','My', 'Ours','And' 'Us'] \n",
    "for article in new_article:\n",
    "    ans=0\n",
    "    for word in article:\n",
    "        if word in personal_noun:\n",
    "            ans+=1\n",
    "    personal_nouns.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfd117f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUN'] = personal_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0e76c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AVG WORD LENGTH'] = np.array(total_characters)/np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da98cf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCES</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUN</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.060011</td>\n",
       "      <td>26.129870</td>\n",
       "      <td>0.301193</td>\n",
       "      <td>10.572425</td>\n",
       "      <td>26.129870</td>\n",
       "      <td>606</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.859841</td>\n",
       "      <td>39</td>\n",
       "      <td>5.160040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>71</td>\n",
       "      <td>38</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.074863</td>\n",
       "      <td>20.525000</td>\n",
       "      <td>0.195493</td>\n",
       "      <td>8.288197</td>\n",
       "      <td>20.525000</td>\n",
       "      <td>321</td>\n",
       "      <td>1642</td>\n",
       "      <td>1.542631</td>\n",
       "      <td>37</td>\n",
       "      <td>4.302680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>74</td>\n",
       "      <td>38</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.064479</td>\n",
       "      <td>22.552941</td>\n",
       "      <td>0.279082</td>\n",
       "      <td>9.132809</td>\n",
       "      <td>22.552941</td>\n",
       "      <td>535</td>\n",
       "      <td>1917</td>\n",
       "      <td>1.811163</td>\n",
       "      <td>31</td>\n",
       "      <td>4.912363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.067146</td>\n",
       "      <td>19.284211</td>\n",
       "      <td>0.199782</td>\n",
       "      <td>7.793597</td>\n",
       "      <td>19.284211</td>\n",
       "      <td>366</td>\n",
       "      <td>1832</td>\n",
       "      <td>1.581332</td>\n",
       "      <td>74</td>\n",
       "      <td>4.428493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>69</td>\n",
       "      <td>28</td>\n",
       "      <td>0.422680</td>\n",
       "      <td>0.053151</td>\n",
       "      <td>25.050633</td>\n",
       "      <td>0.210207</td>\n",
       "      <td>10.104336</td>\n",
       "      <td>25.050633</td>\n",
       "      <td>416</td>\n",
       "      <td>1979</td>\n",
       "      <td>1.643759</td>\n",
       "      <td>36</td>\n",
       "      <td>4.612936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146.0</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.058761</td>\n",
       "      <td>20.673469</td>\n",
       "      <td>0.237907</td>\n",
       "      <td>8.364551</td>\n",
       "      <td>20.673469</td>\n",
       "      <td>241</td>\n",
       "      <td>1013</td>\n",
       "      <td>1.714709</td>\n",
       "      <td>15</td>\n",
       "      <td>4.950642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147.0</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.037148</td>\n",
       "      <td>28.451613</td>\n",
       "      <td>0.235828</td>\n",
       "      <td>11.474976</td>\n",
       "      <td>28.451613</td>\n",
       "      <td>416</td>\n",
       "      <td>1764</td>\n",
       "      <td>1.641723</td>\n",
       "      <td>42</td>\n",
       "      <td>4.667234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148.0</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.179487</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>19.636364</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>7.960718</td>\n",
       "      <td>19.636364</td>\n",
       "      <td>344</td>\n",
       "      <td>1296</td>\n",
       "      <td>1.711420</td>\n",
       "      <td>20</td>\n",
       "      <td>4.658179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149.0</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.054201</td>\n",
       "      <td>27.275862</td>\n",
       "      <td>0.294564</td>\n",
       "      <td>11.028170</td>\n",
       "      <td>27.275862</td>\n",
       "      <td>233</td>\n",
       "      <td>791</td>\n",
       "      <td>1.895070</td>\n",
       "      <td>8</td>\n",
       "      <td>5.260430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150.0</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>47</td>\n",
       "      <td>41</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.084050</td>\n",
       "      <td>17.424242</td>\n",
       "      <td>0.228696</td>\n",
       "      <td>7.061175</td>\n",
       "      <td>17.424242</td>\n",
       "      <td>263</td>\n",
       "      <td>1150</td>\n",
       "      <td>1.733913</td>\n",
       "      <td>8</td>\n",
       "      <td>4.673043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0      37.0  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1      38.0  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2      39.0  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3      40.0  https://insights.blackcoffer.com/will-machine-...   \n",
       "4      41.0  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109   146.0  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110   147.0  https://insights.blackcoffer.com/the-future-of...   \n",
       "111   148.0  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112   149.0  https://insights.blackcoffer.com/business-anal...   \n",
       "113   150.0  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0                76              34        0.381818            0.060011   \n",
       "1                71              38        0.302752            0.074863   \n",
       "2                74              38        0.321429            0.064479   \n",
       "3                84              28        0.500000            0.067146   \n",
       "4                69              28        0.422680            0.053151   \n",
       "..              ...             ...             ...                 ...   \n",
       "109              28              27        0.018182            0.058761   \n",
       "110              46              16        0.483871            0.037148   \n",
       "111              32              46       -0.179487            0.065217   \n",
       "112              36               4        0.800000            0.054201   \n",
       "113              47              41        0.068182            0.084050   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0              26.129870                     0.301193  10.572425   \n",
       "1              20.525000                     0.195493   8.288197   \n",
       "2              22.552941                     0.279082   9.132809   \n",
       "3              19.284211                     0.199782   7.793597   \n",
       "4              25.050633                     0.210207  10.104336   \n",
       "..                   ...                          ...        ...   \n",
       "109            20.673469                     0.237907   8.364551   \n",
       "110            28.451613                     0.235828  11.474976   \n",
       "111            19.636364                     0.265432   7.960718   \n",
       "112            27.275862                     0.294564  11.028170   \n",
       "113            17.424242                     0.228696   7.061175   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCES  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                            26.129870                 606        2012   \n",
       "1                            20.525000                 321        1642   \n",
       "2                            22.552941                 535        1917   \n",
       "3                            19.284211                 366        1832   \n",
       "4                            25.050633                 416        1979   \n",
       "..                                 ...                 ...         ...   \n",
       "109                          20.673469                 241        1013   \n",
       "110                          28.451613                 416        1764   \n",
       "111                          19.636364                 344        1296   \n",
       "112                          27.275862                 233         791   \n",
       "113                          17.424242                 263        1150   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUN  AVG WORD LENGTH  \n",
       "0             1.859841                39         5.160040  \n",
       "1             1.542631                37         4.302680  \n",
       "2             1.811163                31         4.912363  \n",
       "3             1.581332                74         4.428493  \n",
       "4             1.643759                36         4.612936  \n",
       "..                 ...               ...              ...  \n",
       "109           1.714709                15         4.950642  \n",
       "110           1.641723                42         4.667234  \n",
       "111           1.711420                20         4.658179  \n",
       "112           1.895070                 8         5.260430  \n",
       "113           1.733913                 8         4.673043  \n",
       "\n",
       "[111 rows x 15 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final dataframe is printed.\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ead0bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe prepared is stored in a CSV file called ASSIGNMENT SOLUTION.csv. \n",
    "\n",
    "df.to_csv('ASSIGNMENT SOLUTION.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf7d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
